{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We predicted the \"conversion\" events through identifying the general topics using $\\textbf{interest_topics.csv}$.\n",
    "- We then extracted the number of sub topics for each main topic and created a new feature called $\\textbf{sub_topics}$. Using this feature, we identified each customer's breadth of interests. We further analyzed this feature and found it helpful in predicting conversion events. \n",
    "- We sampled the same number of position and negative instances in the training set, after that we used \"decision tree\" \"random forest\" \"adaboost\" \"gradient boosting\" etc. algorithms to predicte the \"conversion\" events from customers.  The higest mean  CV score for the training data set is from \"random forest\" which is 67.3%, and the highest accuracy is 69.3% in the validation set with \"random forest\" algorithms.\n",
    "- Analysis of this dataset is conducted by Yukun Jin <yj139@duke.edu> and Shan Yang <syang0827@gmail.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>inAudience</th>\n",
       "      <th>ltiFeatures</th>\n",
       "      <th>stiFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>{'89': 0.0027281240558934, '1264': 0.001862958...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'47': 0.0019292939671486482, '1187': 0.012261...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>{'45': 0.001961152113619305, '47': 0.001584126...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>{'1253': 0.006566573072362829, '1164': 0.00327...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>{'78': 0.013096540307802428, '1198': 0.0025546...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  inAudience                                        ltiFeatures  \\\n",
       "0       0        True  {'89': 0.0027281240558934, '1264': 0.001862958...   \n",
       "1       1        True  {'47': 0.0019292939671486482, '1187': 0.012261...   \n",
       "2       2        True  {'45': 0.001961152113619305, '47': 0.001584126...   \n",
       "3       3        True  {'1253': 0.006566573072362829, '1164': 0.00327...   \n",
       "4       4        True  {'78': 0.013096540307802428, '1198': 0.0025546...   \n",
       "\n",
       "  stiFeatures  \n",
       "0          {}  \n",
       "1          {}  \n",
       "2          {}  \n",
       "3          {}  \n",
       "4          {}  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def load(file):\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # convert the column values from literal string to dictionary\n",
    "    df['ltiFeatures'] = df['ltiFeatures'].apply(ast.literal_eval)\n",
    "    df['stiFeatures'] = df['stiFeatures'].apply(ast.literal_eval)\n",
    "\n",
    "    return df\n",
    "\n",
    "# load all the data\n",
    "training = load(\"valassis_dataset/training.csv\")\n",
    "validation = load(\"valassis_dataset/validation.csv\")\n",
    "interest_topics = pd.read_csv(\"valassis_dataset/interest_topics.csv\")\n",
    "\n",
    "# inspect the data\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>/Arts &amp; Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>/Computers &amp; Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>/Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>/Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>/Home &amp; Garden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id                topic_name\n",
       "0         3     /Arts & Entertainment\n",
       "1         5  /Computers & Electronics\n",
       "2         7                  /Finance\n",
       "3         8                    /Games\n",
       "4        11            /Home & Garden"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interest_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>inAudience</th>\n",
       "      <th>ltiFeatures</th>\n",
       "      <th>stiFeatures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>{'45': 0.020536141517834786, '47': 0.003117529...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>{'45': 0.001158253110658664, '592': 0.01546380...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>{'908': 0.002470851264264668, '590': 0.0021402...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>{'1187': 0.001127974558171163, '1780': 0.00117...</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>{'907': 0.025339209040149392, '1187': 0.006020...</td>\n",
       "      <td>{'907': 0.10445132121076425, '908': 0.05651522...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  inAudience                                        ltiFeatures  \\\n",
       "0       1        True  {'45': 0.020536141517834786, '47': 0.003117529...   \n",
       "1       2        True  {'45': 0.001158253110658664, '592': 0.01546380...   \n",
       "2       3        True  {'908': 0.002470851264264668, '590': 0.0021402...   \n",
       "3       4        True  {'1187': 0.001127974558171163, '1780': 0.00117...   \n",
       "4       5        True  {'907': 0.025339209040149392, '1187': 0.006020...   \n",
       "\n",
       "                                         stiFeatures  \n",
       "0                                                 {}  \n",
       "1                                                 {}  \n",
       "2                                                 {}  \n",
       "3                                                 {}  \n",
       "4  {'907': 0.10445132121076425, '908': 0.05651522...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the training dataset's inAudience value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inAudience\n",
       "False    94941\n",
       "True      1465\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.groupby('inAudience').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " After inspecting the inAudience value of the training dataset,we found that the dataset is imbalanced, therefore, we decide to resample the data before applying our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We first extracted the main topic from the $\\textit{topic_name}$ feature and created a $\\textbf{main_topic_mapping}$ dictionary structure to store the $\\textit{main_topic}$ as the $\\textbf{key}$ and a list structure that holds different $\\textit{topic_id}$ that belongs to the same main topic.\n",
    "- Then we reasoned that it is possible for a user that has more detailed interests to be converted. By this we mean that if a user has interests in lots of subtopics then it is more possible that the user would be convereted. Therefore, we create a new feature that called $\\textit{topic_name}$ to count the layers a topic have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>sub_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>/Arts &amp; Entertainment</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>/Computers &amp; Electronics</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>/Finance</td>\n",
       "      <td>Finance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>/Games</td>\n",
       "      <td>Games</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>/Home &amp; Garden</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>/Business &amp; Industrial</td>\n",
       "      <td>Business &amp; Industrial</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>/Internet &amp; Telecom</td>\n",
       "      <td>Internet &amp; Telecom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>/People &amp; Society</td>\n",
       "      <td>People &amp; Society</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>/News</td>\n",
       "      <td>News</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>/Shopping</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>/Law &amp; Government</td>\n",
       "      <td>Law &amp; Government</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20</td>\n",
       "      <td>/Sports</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>/Books &amp; Literature</td>\n",
       "      <td>Books &amp; Literature</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>23</td>\n",
       "      <td>/Arts &amp; Entertainment/Performing Arts</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24</td>\n",
       "      <td>/Arts &amp; Entertainment/Visual Art &amp; Design</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25</td>\n",
       "      <td>/Business &amp; Industrial/Advertising &amp; Marketing</td>\n",
       "      <td>Business &amp; Industrial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>28</td>\n",
       "      <td>/Business &amp; Industrial/Business Services/Offic...</td>\n",
       "      <td>Business &amp; Industrial</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29</td>\n",
       "      <td>/Real Estate</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30</td>\n",
       "      <td>/Computers &amp; Electronics/Computer Hardware</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>31</td>\n",
       "      <td>/Computers &amp; Electronics/Programming</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>32</td>\n",
       "      <td>/Computers &amp; Electronics/Software</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>33</td>\n",
       "      <td>/Arts &amp; Entertainment/Offbeat</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>34</td>\n",
       "      <td>/Arts &amp; Entertainment/Movies</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>35</td>\n",
       "      <td>/Arts &amp; Entertainment/Music &amp; Audio</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>36</td>\n",
       "      <td>/Arts &amp; Entertainment/TV &amp; Video</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>37</td>\n",
       "      <td>/Finance/Banking</td>\n",
       "      <td>Finance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>38</td>\n",
       "      <td>/Finance/Insurance</td>\n",
       "      <td>Finance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39</td>\n",
       "      <td>/Games/Card Games</td>\n",
       "      <td>Games</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>41</td>\n",
       "      <td>/Games/Computer &amp; Video Games</td>\n",
       "      <td>Games</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>42</td>\n",
       "      <td>/Arts &amp; Entertainment/Music &amp; Audio/Jazz &amp; Blu...</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>1738</td>\n",
       "      <td>/People &amp; Society/Family &amp; Relationships/Famil...</td>\n",
       "      <td>People &amp; Society</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>1739</td>\n",
       "      <td>/Computers &amp; Electronics/Software/Multimedia S...</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>1740</td>\n",
       "      <td>/Computers &amp; Electronics/Software/Multimedia S...</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>1741</td>\n",
       "      <td>/People &amp; Society/Family &amp; Relationships/Famil...</td>\n",
       "      <td>People &amp; Society</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>1747</td>\n",
       "      <td>/Autos &amp; Vehicles/Vehicle Parts &amp; Services/Veh...</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>1748</td>\n",
       "      <td>/Autos &amp; Vehicles/Vehicle Parts &amp; Services/Veh...</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>1750</td>\n",
       "      <td>/Autos &amp; Vehicles/Vehicle Parts &amp; Services/Veh...</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>1751</td>\n",
       "      <td>/Autos &amp; Vehicles/Vehicle Parts &amp; Services/Veh...</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>1757</td>\n",
       "      <td>/Shopping/Photo &amp; Video Services/Event &amp; Studi...</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>1758</td>\n",
       "      <td>/Shopping/Photo &amp; Video Services/Photo Printin...</td>\n",
       "      <td>Shopping</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>1763</td>\n",
       "      <td>/Beauty &amp; Fitness/Fitness/Fitness Equipment &amp; ...</td>\n",
       "      <td>Beauty &amp; Fitness</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>1779</td>\n",
       "      <td>/Arts &amp; Entertainment/Humor/Funny Pictures &amp; V...</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>1780</td>\n",
       "      <td>/Arts &amp; Entertainment/TV &amp; Video/Online Video/...</td>\n",
       "      <td>Arts &amp; Entertainment</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>1783</td>\n",
       "      <td>/Autos &amp; Vehicles/Motor Vehicles (By Brand)/Ra...</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>1784</td>\n",
       "      <td>/Autos &amp; Vehicles/Motor Vehicles (By Brand)/Te...</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>1785</td>\n",
       "      <td>/Computers &amp; Electronics/Computer Hardware/Com...</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1786</td>\n",
       "      <td>/Computers &amp; Electronics/Consumer Electronics/...</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1787</td>\n",
       "      <td>/Computers &amp; Electronics/Consumer Electronics/...</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>1788</td>\n",
       "      <td>/Computers &amp; Electronics/Consumer Electronics/...</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>1789</td>\n",
       "      <td>/Computers &amp; Electronics/Consumer Electronics/...</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>1790</td>\n",
       "      <td>/Computers &amp; Electronics/Consumer Electronics/...</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1791</td>\n",
       "      <td>/Computers &amp; Electronics/Consumer Electronics/...</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>1795</td>\n",
       "      <td>/Finance/Investing/Currencies &amp; Foreign Exchan...</td>\n",
       "      <td>Finance</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>1799</td>\n",
       "      <td>/Games/Computer &amp; Video Games/Sandbox Games</td>\n",
       "      <td>Games</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>1800</td>\n",
       "      <td>/Home &amp; Garden/HVAC &amp; Climate Control/Air Filt...</td>\n",
       "      <td>Home &amp; Garden</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>1801</td>\n",
       "      <td>/Jobs &amp; Education/Education/Private Tutoring S...</td>\n",
       "      <td>Jobs &amp; Education</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>1802</td>\n",
       "      <td>/Computers &amp; Electronics/Consumer Electronics/...</td>\n",
       "      <td>Computers &amp; Electronics</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>1804</td>\n",
       "      <td>/Sports/Sports Fan Gear &amp; Apparel</td>\n",
       "      <td>Sports</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1820</td>\n",
       "      <td>/Finance/Credit &amp; Lending/Loans/Vehicle Financ...</td>\n",
       "      <td>Finance</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1826</td>\n",
       "      <td>/Food &amp; Drink/Cooking &amp; Recipes/Desserts/Ice C...</td>\n",
       "      <td>Food &amp; Drink</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1411 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic_id                                         topic_name  \\\n",
       "0            3                              /Arts & Entertainment   \n",
       "1            5                           /Computers & Electronics   \n",
       "2            7                                           /Finance   \n",
       "3            8                                             /Games   \n",
       "4           11                                     /Home & Garden   \n",
       "5           12                             /Business & Industrial   \n",
       "6           13                                /Internet & Telecom   \n",
       "7           14                                  /People & Society   \n",
       "8           16                                              /News   \n",
       "9           18                                          /Shopping   \n",
       "10          19                                  /Law & Government   \n",
       "11          20                                            /Sports   \n",
       "12          22                                /Books & Literature   \n",
       "13          23              /Arts & Entertainment/Performing Arts   \n",
       "14          24          /Arts & Entertainment/Visual Art & Design   \n",
       "15          25     /Business & Industrial/Advertising & Marketing   \n",
       "16          28  /Business & Industrial/Business Services/Offic...   \n",
       "17          29                                       /Real Estate   \n",
       "18          30         /Computers & Electronics/Computer Hardware   \n",
       "19          31               /Computers & Electronics/Programming   \n",
       "20          32                  /Computers & Electronics/Software   \n",
       "21          33                      /Arts & Entertainment/Offbeat   \n",
       "22          34                       /Arts & Entertainment/Movies   \n",
       "23          35                /Arts & Entertainment/Music & Audio   \n",
       "24          36                   /Arts & Entertainment/TV & Video   \n",
       "25          37                                   /Finance/Banking   \n",
       "26          38                                 /Finance/Insurance   \n",
       "27          39                                  /Games/Card Games   \n",
       "28          41                      /Games/Computer & Video Games   \n",
       "29          42  /Arts & Entertainment/Music & Audio/Jazz & Blu...   \n",
       "...        ...                                                ...   \n",
       "1381      1738  /People & Society/Family & Relationships/Famil...   \n",
       "1382      1739  /Computers & Electronics/Software/Multimedia S...   \n",
       "1383      1740  /Computers & Electronics/Software/Multimedia S...   \n",
       "1384      1741  /People & Society/Family & Relationships/Famil...   \n",
       "1385      1747  /Autos & Vehicles/Vehicle Parts & Services/Veh...   \n",
       "1386      1748  /Autos & Vehicles/Vehicle Parts & Services/Veh...   \n",
       "1387      1750  /Autos & Vehicles/Vehicle Parts & Services/Veh...   \n",
       "1388      1751  /Autos & Vehicles/Vehicle Parts & Services/Veh...   \n",
       "1389      1757  /Shopping/Photo & Video Services/Event & Studi...   \n",
       "1390      1758  /Shopping/Photo & Video Services/Photo Printin...   \n",
       "1391      1763  /Beauty & Fitness/Fitness/Fitness Equipment & ...   \n",
       "1392      1779  /Arts & Entertainment/Humor/Funny Pictures & V...   \n",
       "1393      1780  /Arts & Entertainment/TV & Video/Online Video/...   \n",
       "1394      1783  /Autos & Vehicles/Motor Vehicles (By Brand)/Ra...   \n",
       "1395      1784  /Autos & Vehicles/Motor Vehicles (By Brand)/Te...   \n",
       "1396      1785  /Computers & Electronics/Computer Hardware/Com...   \n",
       "1397      1786  /Computers & Electronics/Consumer Electronics/...   \n",
       "1398      1787  /Computers & Electronics/Consumer Electronics/...   \n",
       "1399      1788  /Computers & Electronics/Consumer Electronics/...   \n",
       "1400      1789  /Computers & Electronics/Consumer Electronics/...   \n",
       "1401      1790  /Computers & Electronics/Consumer Electronics/...   \n",
       "1402      1791  /Computers & Electronics/Consumer Electronics/...   \n",
       "1403      1795  /Finance/Investing/Currencies & Foreign Exchan...   \n",
       "1404      1799        /Games/Computer & Video Games/Sandbox Games   \n",
       "1405      1800  /Home & Garden/HVAC & Climate Control/Air Filt...   \n",
       "1406      1801  /Jobs & Education/Education/Private Tutoring S...   \n",
       "1407      1802  /Computers & Electronics/Consumer Electronics/...   \n",
       "1408      1804                  /Sports/Sports Fan Gear & Apparel   \n",
       "1409      1820  /Finance/Credit & Lending/Loans/Vehicle Financ...   \n",
       "1410      1826  /Food & Drink/Cooking & Recipes/Desserts/Ice C...   \n",
       "\n",
       "                   main_topic  sub_topics  \n",
       "0        Arts & Entertainment           0  \n",
       "1     Computers & Electronics           0  \n",
       "2                     Finance           0  \n",
       "3                       Games           0  \n",
       "4               Home & Garden           0  \n",
       "5       Business & Industrial           0  \n",
       "6          Internet & Telecom           0  \n",
       "7            People & Society           0  \n",
       "8                        News           0  \n",
       "9                    Shopping           0  \n",
       "10           Law & Government           0  \n",
       "11                     Sports           0  \n",
       "12         Books & Literature           0  \n",
       "13       Arts & Entertainment           1  \n",
       "14       Arts & Entertainment           1  \n",
       "15      Business & Industrial           1  \n",
       "16      Business & Industrial           2  \n",
       "17                Real Estate           0  \n",
       "18    Computers & Electronics           1  \n",
       "19    Computers & Electronics           1  \n",
       "20    Computers & Electronics           1  \n",
       "21       Arts & Entertainment           1  \n",
       "22       Arts & Entertainment           1  \n",
       "23       Arts & Entertainment           1  \n",
       "24       Arts & Entertainment           1  \n",
       "25                    Finance           1  \n",
       "26                    Finance           1  \n",
       "27                      Games           1  \n",
       "28                      Games           1  \n",
       "29       Arts & Entertainment           3  \n",
       "...                       ...         ...  \n",
       "1381         People & Society           5  \n",
       "1382  Computers & Electronics           4  \n",
       "1383  Computers & Electronics           4  \n",
       "1384         People & Society           5  \n",
       "1385         Autos & Vehicles           3  \n",
       "1386         Autos & Vehicles           3  \n",
       "1387         Autos & Vehicles           3  \n",
       "1388         Autos & Vehicles           3  \n",
       "1389                 Shopping           2  \n",
       "1390                 Shopping           2  \n",
       "1391         Beauty & Fitness           3  \n",
       "1392     Arts & Entertainment           2  \n",
       "1393     Arts & Entertainment           3  \n",
       "1394         Autos & Vehicles           2  \n",
       "1395         Autos & Vehicles           2  \n",
       "1396  Computers & Electronics           4  \n",
       "1397  Computers & Electronics           5  \n",
       "1398  Computers & Electronics           2  \n",
       "1399  Computers & Electronics           3  \n",
       "1400  Computers & Electronics           2  \n",
       "1401  Computers & Electronics           2  \n",
       "1402  Computers & Electronics           2  \n",
       "1403                  Finance           3  \n",
       "1404                    Games           2  \n",
       "1405            Home & Garden           2  \n",
       "1406         Jobs & Education           2  \n",
       "1407  Computers & Electronics           4  \n",
       "1408                   Sports           1  \n",
       "1409                  Finance           5  \n",
       "1410             Food & Drink           3  \n",
       "\n",
       "[1411 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interest_topics['main_topic'] = interest_topics['topic_name'].str.split('/',expand = True)[1]\n",
    "interest_topics['sub_topics'] = interest_topics['topic_name'].str.count('/')-1\n",
    "interest_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_topic_mapping = {} # A dictionary structure key:main_topic values:[topic_id]\n",
    "topic_id_list = interest_topics['topic_id']\n",
    "main_topics = interest_topics['main_topic']\n",
    "for main_topic,tid in zip(main_topics,topic_id_list):\n",
    "    if main_topic not in main_topic_mapping:\n",
    "        main_topic_mapping[main_topic] = []\n",
    "    else:\n",
    "        main_topic_mapping[main_topic].append(str(tid))\n",
    "sub_topics_mapping = interest_topics['sub_topics'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After doing the feature engineering on the $\\textbf{interest_topics}$ dataset, we used two mappings that we extracted to aggregate the interest proportions for each user in the training dataset. One reasons for aggregating the interest proportions is to simplify the amounts of features, and another reason for aggregating the interest proportions is that we found some user would have interests in some sub topics that have the same main topic. Therefore, it is reasonale to aggregate the interest proportions.\n",
    "- We then used the $\\textbf{sub_topics_mapping}$ to compute the total sub topics interested for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateInterest(df,main_topic_mapping):\n",
    "    features = ['ltiFeatures','stiFeatures']\n",
    "    for feature in features:\n",
    "        df_feature = df[feature]\n",
    "        for main_topic in main_topic_mapping:\n",
    "            aggInt = pd.DataFrame.from_records(df_feature,columns = np.array(main_topic_mapping[main_topic]))\n",
    "            aggInt.fillna(0)\n",
    "            if feature == 'ltiFeatures':\n",
    "                df[main_topic+'_l'] = aggInt.sum(axis=1)\n",
    "            else:\n",
    "                df[main_topic+'_s'] = aggInt.sum(axis=1)\n",
    "    return df\n",
    "def computeSubTopics(df,sub_topics_mapping):\n",
    "    sub_topics = []\n",
    "    for user in df['ltiFeatures']:\n",
    "        tot = 0\n",
    "        for interest in user:\n",
    "            if int(interest) not in sub_topics_mapping:\n",
    "                continue\n",
    "            tot = tot + sub_topics_mapping[int(interest)]\n",
    "        sub_topics.append(tot)\n",
    "    df['sub_topics'] = np.array(sub_topics)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bc14e7bad677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregateInterest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmain_topic_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputeSubTopics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_topics_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df_test = aggregateInterest(training,main_topic_mapping)\n",
    "df_test = computeSubTopics(df,sub_topics_mapping)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = aggregateInterest(validation,main_topic_mapping)\n",
    "df_val = computeSubTopics(df_val,sub_topics_mapping)\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_majority =df[df.inAudience == False]\n",
    "df_minority =df[df.inAudience == True]\n",
    "df_majority_downsampled = resample(df_majority, replace = False, \n",
    "                                   n_samples = 1465)\n",
    "df_downsampled = pd.concat([df_majority_downsampled,df_minority])\n",
    "df_downsampled.inAudience.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_major = df_val[df_val.inAudience == False]\n",
    "val_minor = df_val[df_val.inAudience == True]\n",
    "val_major_resampled = resample(val_major,replace = False,n_samples = 620)\n",
    "val_downsampled = pd.concat([val_major_resampled,val_minor])\n",
    "val_downsampled.inAudience.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section, we decided to use plots to select features that we think could have high significance on differentiating the classes. We mainly used box plots to see the distribution of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_features = []\n",
    "for col in df_downsampled.columns[4:-1]:\n",
    "    topic_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df,features):\n",
    "    df_true = df[df.inAudience == True]\n",
    "    df_false = df[df.inAudience == False]\n",
    "    for feature in features:\n",
    "        fig,axes = plt.subplots(1,2)\n",
    "        axes[0].hist(df_true[feature])\n",
    "        axes[0].set_xlabel(feature)\n",
    "        axes[0].set_ylabel('freq')\n",
    "        axes[0].set_title('inAudience = True')\n",
    "        axes[1].hist(df_false[feature])\n",
    "        axes[1].set_xlabel(feature)\n",
    "        axes[1].set_ylabel('freq')\n",
    "        axes[1].set_title('inAudience = False')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(df_downsampled,topic_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eventhough distributions of most features are left-skewed, we still could get some insights from these hitograms. For example, we see that for $\\textbf{Arts & Entertainment_l}$, the distribution of converted customers is different from non-converted customers. Following this methodology, we selected following features [$\\textbf{'Arts & Entertainment_l','News_l','Shopping_l','Books & Literature_l','Health_l','Autos & Vehicles_l','Finance_s'}$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(training['sub_topics'].loc[:1465])\n",
    "plt.xlabel('# of sub topics')\n",
    "plt.ylabel('freq')\n",
    "plt.title('Distribution Analysis of sub_topics feature')\n",
    "plt.show()\n",
    "sns.distplot(training['sub_topics'].loc[1465:])\n",
    "plt.xlabel('# of sub topics')\n",
    "plt.ylabel('freq')\n",
    "plt.title('Distribution Analysis of sub_topics feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the distribution of $\\textbf{sub_topics}$ shows that indeed for some converted customers, they tend to be interested in more sub topics. Therefore, it confirmed our suspect and we decided to use this as one of our input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = ['Arts & Entertainment_l','Health_l','Autos & Vehicles_l','Finance_s','sub_topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_downsampled[input_features]\n",
    "y = df_downsampled['inAudience'].replace(y_mapping)\n",
    "X_validate =val_downsampled[input_features]\n",
    "y_validate = val_downsampled['inAudience'].replace(y_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turkey's Method For Multiple outliers detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the distribution analysis for each feature, we found that there are outliers for each feature, therefore, we use Turkey's Method to detect if an observation has multiple outliers in different features. And drop that observation from our dataset.\n",
    "- The following code is an implementation of Turkey's Method from the interenet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def detect_outliers(df, n, features):\n",
    "    \"\"\"\n",
    "    Takes a dataframe df of features and returns a list of the indices\n",
    "    corresponding to the observations containing more than n outliers according\n",
    "    to the Tukey method.\n",
    "    \"\"\"\n",
    "    outlier_indices = []\n",
    "\n",
    "    # iterate over features(columns)\n",
    "    for col in features:\n",
    "        # 1st quartile (25%)\n",
    "        Q1 = np.percentile(df[col], 25)\n",
    "        # 3rd quartile (75%)\n",
    "        Q3 = np.percentile(df[col], 75)\n",
    "        # Interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "\n",
    "        # Determine a list of indices of outliers for feature col\n",
    "        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step)].index\n",
    "\n",
    "        # append the found outlier indices for col to the list of outlier indices \n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "\n",
    "    # select observations containing more than 2 outliers\n",
    "    outlier_indices = Counter(outlier_indices)        \n",
    "    multiple_outliers = list(k for k, v in outlier_indices.items() if v > n)\n",
    "\n",
    "    return multiple_outliers\n",
    "\n",
    "# detect outliers from list of features\n",
    "\n",
    "#drop outliers in training\n",
    "Outliers_to_drop = detect_outliers(df_downsampled, 2, input_features)\n",
    "df_downsampled.drop(Outliers_to_drop,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Validating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section we trained different ML models, specifically $\\textbf{Decision Tree,Random Forest,AdaBoost,Gradient Boosting,XGBoost}$, the first get the training accuracy, and then did a 5-fold cross-validation on the resampled validation set to determine the best model.\n",
    "- We used GridCVSearch to search the best parameters for a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = df_val[features]\n",
    "y_validate = df_val['inAudience'].replace(y_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 2019)\n",
    "param = {'criterion':['gini','entropy'],\n",
    "        'max_depth':[3,6,9],\n",
    "        'min_samples_split':[2,3,5],\n",
    "        'min_samples_leaf':[1,5,8],\n",
    "        'max_features':['auto','sqrt','log2']\n",
    "        }\n",
    "grid = GridSearchCV(clf,param,scoring = 'accuracy')\n",
    "grid = grid.fit(X,y)\n",
    "clf = grid.best_estimator_\n",
    "print('Model:')\n",
    "print(clf)\n",
    "clf.fit(X,y)\n",
    "pred = clf.predict(X)\n",
    "print('Accuracy Score on training dataset: ')\n",
    "print(accuracy_score(y,pred))\n",
    "print('-----')\n",
    "print('5-fold Cross Validation Score:')\n",
    "cross_val = cross_val_score(clf,X,y,cv = 5)\n",
    "print(cross_val)\n",
    "print('-----')\n",
    "print('Mean CV score:')\n",
    "print(np.mean(cross_val))\n",
    "y_pred = clf.predict(X_validate)\n",
    "print('-----')\n",
    "print('Accuracy Score on Validation set:')\n",
    "print(accuracy_score(y_validate,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf  = RandomForestClassifier(random_state = 2019)\n",
    "param = {'n_estimators':[4,6,9],\n",
    "         'max_features':['log2','sqrt','auto'],\n",
    "         'criterion':['entropy','gini'],\n",
    "        'max_depth':[2,3,5,10],\n",
    "        'min_samples_split':[2,3,5],\n",
    "        'min_samples_leaf':[1,5,8]\n",
    "        }\n",
    "grid = GridSearchCV(clf,param,scoring = 'accuracy')\n",
    "grid = grid.fit(X,y)\n",
    "clf = grid.best_estimator_\n",
    "print('Model:')\n",
    "print(clf)\n",
    "clf.fit(X,y)\n",
    "pred = clf.predict(X)\n",
    "print('Accuracy Score on training dataset: ')\n",
    "print(accuracy_score(y,pred))\n",
    "print('-----')\n",
    "print('5-fold Cross Validation Score:')\n",
    "cross_val = cross_val_score(clf,X,y,cv = 5)\n",
    "print(cross_val)\n",
    "print('-----')\n",
    "print('Mean CV score:')\n",
    "print(np.mean(cross_val))\n",
    "y_pred = clf.predict(X_validate)\n",
    "print('-----')\n",
    "print('Accuracy Score on Validation set:')\n",
    "print(accuracy_score(y_validate,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(random_state = 2019)\n",
    "param = {'n_estimators':[50,100,150,200,250],\n",
    "        'learning_rate':[0.01,0.1,1],\n",
    "        'algorithm':['SAMME','SAMME.R']\n",
    "        }\n",
    "grid = GridSearchCV(clf,param,scoring = 'accuracy')\n",
    "grid = grid.fit(X,y)\n",
    "clf = grid.best_estimator_\n",
    "print('Model:')\n",
    "print(clf)\n",
    "clf.fit(X,y)\n",
    "pred = clf.predict(X)\n",
    "print('Accuracy Score on training dataset: ')\n",
    "print(accuracy_score(y,pred))\n",
    "print('-----')\n",
    "print('5-fold Cross Validation Score:')\n",
    "cross_val = cross_val_score(clf,X,y,cv = 5)\n",
    "print(cross_val)\n",
    "print('-----')\n",
    "print('Mean CV score:')\n",
    "print(np.mean(cross_val))\n",
    "y_pred = clf.predict(X_validate)\n",
    "print('-----')\n",
    "print('Accuracy Score on Validation set:')\n",
    "print(accuracy_score(y_validate,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(random_state = 2019)\n",
    "param = {'n_estimators':[50,100,150],\n",
    "        'min_samples_split':[2,3,4],\n",
    "        'max_depth':[3,4,5],\n",
    "        'max_features':['auto','sqrt','log2'],\n",
    "        'min_samples_leaf':[1,5,8]}\n",
    "grid = GridSearchCV(clf,param,scoring = 'accuracy')\n",
    "grid = grid.fit(X,y)\n",
    "clf = grid.best_estimator_\n",
    "print('Model:')\n",
    "print(clf)\n",
    "clf.fit(X,y)\n",
    "pred = clf.predict(X)\n",
    "print('Accuracy Score on training dataset: ')\n",
    "print(accuracy_score(y,pred))\n",
    "print('-----')\n",
    "print('5-fold Cross Validation Score:')\n",
    "cross_val = cross_val_score(clf,X,y,cv = 5)\n",
    "print(cross_val)\n",
    "print('-----')\n",
    "print('Mean CV score:')\n",
    "print(np.mean(cross_val))\n",
    "y_pred = clf.predict(X_validate)\n",
    "print('-----')\n",
    "print('Accuracy Score on Validation set:')\n",
    "print(accuracy_score(y_validate,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier()\n",
    "param = {'eta':[0.1,0.3,0.5,1],\n",
    "        'gamma':[0,3,6],\n",
    "        'max_depth':[3,6,9,10,12],\n",
    "        'subsample':[0.5,1]}\n",
    "grid = GridSearchCV(clf,param,scoring = 'accuracy')\n",
    "grid = grid.fit(X,y)\n",
    "clf = grid.best_estimator_\n",
    "print('Model:')\n",
    "print(clf)\n",
    "clf.fit(X,y)\n",
    "pred = clf.predict(X)\n",
    "print('Accuracy Score on training dataset: ')\n",
    "print(accuracy_score(y,pred))\n",
    "print('-----')\n",
    "print('5-fold Cross Validation Score:')\n",
    "cross_val = cross_val_score(clf,X,y,cv = 5)\n",
    "print(cross_val)\n",
    "print('-----')\n",
    "print('Mean CV score:')\n",
    "print(np.mean(cross_val))\n",
    "y_pred = clf.predict(X_validate)\n",
    "print('-----')\n",
    "print('Accuracy Score on Validation set:')\n",
    "print(accuracy_score(y_validate,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After the training and validating of our models, we see that $\\textbf{Random Forest}$ has the highest mean CV score, therefore, we choose $\\textbf{Random Forest}$ as our final model for this dataset.\n",
    "- Eventhough we see that XGBoost gives a really high accuracy score on the training dataset, the average CV score is not that high, we conclude that XGBoost may overfitted on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given the accuracy score on our models, we conclude that the features we selected are good in general. Therefore, when Valassis looking for rare converted customers from large dataset, we recommend to sepefically look at long term interest in $\\textbf{Arts & Entertainment, Autos & Vehicles}$ and short term interest in $\\textbf{Finance}$\n",
    "- Also, we strongly recommend Valassis to consider the number of sub topics a user would be interested in when predicting if a user would be converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1]: $\\textbf{Turkey's Method}$: https://gist.github.com/joseph-allen/14d72af86689c99e1e225e5771ce1600"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
